{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb15240a",
   "metadata": {},
   "source": [
    "# Pool and Split Data\n",
    "\n",
    "Get all the data and split it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e9b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import wave\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e61feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_and_split_data(root_dir, path_to_files, type_of_sound, delete_invalid=True):\n",
    "    \"\"\"\n",
    "    1. Pool all valid data into one folder\n",
    "    2. Split the data into training (80%) and testing (20%) sets\n",
    "    3. Process the data into an appropriate format for ML\n",
    "    \"\"\"\n",
    "    # Create necessary directories\n",
    "    all_data_dir = f'{root_dir}/all_data_{type_of_sound}'\n",
    "    training_dir = f'{root_dir}/training_{type_of_sound}'\n",
    "    testing_dir = f'{root_dir}/testing_{type_of_sound}'\n",
    "    \n",
    "    os.makedirs(all_data_dir, exist_ok=True)\n",
    "    os.makedirs(training_dir, exist_ok=True)\n",
    "    os.makedirs(testing_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all valid WAV files across splits\n",
    "    splits = ['balanced_train', 'unbalanced_train', 'eval']\n",
    "    all_valid_files = []\n",
    "    \n",
    "    print(\"Step 1: Checking and pooling valid files...\")\n",
    "    for split in splits:\n",
    "        data_path = f'{path_to_files}{split}'\n",
    "        engine_knocking_path = os.path.join(data_path, type_of_sound)\n",
    "        \n",
    "        if not os.path.exists(engine_knocking_path):\n",
    "            print(f\"Path does not exist: {engine_knocking_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Get all WAV files in this split\n",
    "        wav_files = []\n",
    "        for root, _, files in os.walk(engine_knocking_path):\n",
    "            wav_files.extend([os.path.join(root, f) for f in files if f.endswith('.wav')])\n",
    "        \n",
    "        print(f\"Found {len(wav_files)} files in {split}\")\n",
    "        \n",
    "        # Validate each file\n",
    "        valid_files = []\n",
    "        for wav_file in tqdm(wav_files, desc=f\"Checking {split} files\"):\n",
    "            try:\n",
    "                # Try to open the file\n",
    "                with wave.open(wav_file, 'rb') as wf:\n",
    "                    # Check if file is empty\n",
    "                    if wf.getnframes() == 0:\n",
    "                        if delete_invalid:\n",
    "                            os.remove(wav_file)\n",
    "                        continue\n",
    "                    \n",
    "                    # Check duration\n",
    "                    frames = wf.getnframes()\n",
    "                    rate = wf.getframerate()\n",
    "                    duration = frames / float(rate)\n",
    "                    \n",
    "                    # Allow some tolerance around 10 seconds\n",
    "                    if abs(duration - 10.0) > 0.5:  # Allow ±0.5 seconds tolerance\n",
    "                        if delete_invalid:\n",
    "                            os.remove(wav_file)\n",
    "                        continue\n",
    "                    \n",
    "                    # If we get here, the file is valid\n",
    "                    valid_files.append(wav_file)\n",
    "            except Exception as e:\n",
    "                if delete_invalid:\n",
    "                    try:\n",
    "                        os.remove(wav_file)\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        all_valid_files.extend(valid_files)\n",
    "    \n",
    "    # Copy all valid files to all_data directory with unique names\n",
    "    print(f\"\\nCopying {len(all_valid_files)} valid files to {all_data_dir}...\")\n",
    "    for i, src_file in enumerate(tqdm(all_valid_files, desc=\"Copying files\")):\n",
    "        filename = f\"engine_knocking_{i+1:04d}.wav\"\n",
    "        dst_file = os.path.join(all_data_dir, filename)\n",
    "        shutil.copy2(src_file, dst_file)\n",
    "    \n",
    "    # Step 2: Split files into training and testing sets\n",
    "    print(\"\\nStep 2: Splitting data into training and testing sets...\")\n",
    "    all_pooled_files = [os.path.join(all_data_dir, f) for f in os.listdir(all_data_dir) if f.endswith('.wav')]\n",
    "    \n",
    "    # Shuffle the files for random split\n",
    "    random.shuffle(all_pooled_files)\n",
    "    \n",
    "    # 80% training, 20% testing\n",
    "    split_idx = int(len(all_pooled_files) * 0.8)\n",
    "    training_files = all_pooled_files[:split_idx]\n",
    "    testing_files = all_pooled_files[split_idx:]\n",
    "    \n",
    "    print(f\"Training set: {len(training_files)} files\")\n",
    "    print(f\"Testing set: {len(testing_files)} files\")\n",
    "    \n",
    "    # Step 3: Process files into the preferred format for ML (Log-Mel Spectrograms)\n",
    "    print(\"\\nStep 3: Processing files into Log-Mel Spectrograms...\")\n",
    "    \n",
    "    def process_file(file, dest_dir, idx, set_name):\n",
    "        \"\"\"Process a single file into a log-mel spectrogram and save as .npy file\"\"\"\n",
    "        try:\n",
    "            # Load audio\n",
    "            y, sr = librosa.load(file, sr=None)\n",
    "            \n",
    "            # Create log-mel spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=y, \n",
    "                sr=sr,\n",
    "                n_fft=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=128,\n",
    "                fmin=20,\n",
    "                fmax=8000\n",
    "            )\n",
    "            \n",
    "            # Convert to log scale\n",
    "            log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "            \n",
    "            # Save as numpy array\n",
    "            output_path = os.path.join(dest_dir, f\"{set_name}_{idx+1:04d}.npy\")\n",
    "            np.save(output_path, log_mel_spec)\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # Process training files\n",
    "    success_count = 0\n",
    "    for idx, file in enumerate(tqdm(training_files, desc=\"Processing training files\")):\n",
    "        if process_file(file, training_dir, idx, \"train\"):\n",
    "            success_count += 1\n",
    "    print(f\"Successfully processed {success_count} training files\")\n",
    "    \n",
    "    # Process testing files\n",
    "    success_count = 0\n",
    "    for idx, file in enumerate(tqdm(testing_files, desc=\"Processing testing files\")):\n",
    "        if process_file(file, testing_dir, idx, \"test\"):\n",
    "            success_count += 1\n",
    "    print(f\"Successfully processed {success_count} testing files\")\n",
    "    \n",
    "    # Create metadata files\n",
    "    with open(os.path.join(training_dir, 'metadata.txt'), 'w') as f:\n",
    "        f.write(f\"Engine knocking training data\\n\")\n",
    "        f.write(f\"Number of samples: {len(training_files)}\\n\")\n",
    "        f.write(f\"Format: Log-Mel Spectrograms (128 mel bands)\\n\")\n",
    "        f.write(f\"Shape: [128, time_frames]\\n\")\n",
    "        f.write(f\"Sample rate: Original\\n\")\n",
    "    \n",
    "    with open(os.path.join(testing_dir, 'metadata.txt'), 'w') as f:\n",
    "        f.write(f\"Engine knocking testing data\\n\")\n",
    "        f.write(f\"Number of samples: {len(testing_files)}\\n\")\n",
    "        f.write(f\"Format: Log-Mel Spectrograms (128 mel bands)\\n\")\n",
    "        f.write(f\"Shape: [128, time_frames]\\n\")\n",
    "        f.write(f\"Sample rate: Original\\n\")\n",
    "    \n",
    "    print(\"\\nData processing complete!\")\n",
    "    print(f\"All valid files: {all_data_dir}/\")\n",
    "    print(f\"Training data: {training_dir}/\")\n",
    "    print(f\"Testing data: {testing_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcc8534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting AudioSet Engine Knocking data pooling and processing...\n",
      "Step 1: Checking and pooling valid files...\n",
      "Found 27 files in balanced_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking balanced_train files: 100%|██████████| 27/27 [00:00<00:00, 8552.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 209 files in unbalanced_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking unbalanced_train files: 100%|██████████| 209/209 [00:00<00:00, 13750.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 files in eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking eval files: 100%|██████████| 21/21 [00:00<00:00, 9429.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying 257 valid files to engine_knocking_data/all_data_Engine knocking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 100%|██████████| 257/257 [00:00<00:00, 421.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Splitting data into training and testing sets...\n",
      "Training set: 205 files\n",
      "Testing set: 52 files\n",
      "\n",
      "Step 3: Processing files into Log-Mel Spectrograms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training files: 100%|██████████| 205/205 [00:05<00:00, 34.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 205 training files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing testing files: 100%|██████████| 52/52 [00:01<00:00, 46.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 52 testing files\n",
      "\n",
      "Data processing complete!\n",
      "All valid files: engine_knocking_data/all_data_Engine knocking/\n",
      "Training data: engine_knocking_data/training_Engine knocking/\n",
      "Testing data: engine_knocking_data/testing_Engine knocking/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting AudioSet Engine Knocking data pooling and processing...\")\n",
    "pool_and_split_data(root_dir='engine_knocking_data', \n",
    "                    path_to_files='engine_knocking_data/engine_knocking_data_', \n",
    "                    type_of_sound=\"Engine knocking\", \n",
    "                    delete_invalid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a42e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting AudioSet Engine Knocking data pooling and processing...\n",
      "Step 1: Checking and pooling valid files...\n",
      "Found 108 files in balanced_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking balanced_train files: 100%|██████████| 108/108 [00:00<00:00, 3204.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 354 files in unbalanced_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking unbalanced_train files: 100%|██████████| 354/354 [00:00<00:00, 5488.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 files in eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking eval files: 100%|██████████| 62/62 [00:00<00:00, 4701.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying 250 valid files to engine_data/all_data_Engine...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 100%|██████████| 250/250 [00:00<00:00, 383.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Splitting data into training and testing sets...\n",
      "Training set: 200 files\n",
      "Testing set: 50 files\n",
      "\n",
      "Step 3: Processing files into Log-Mel Spectrograms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training files: 100%|██████████| 200/200 [00:03<00:00, 50.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200 training files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing testing files: 100%|██████████| 50/50 [00:00<00:00, 50.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 50 testing files\n",
      "\n",
      "Data processing complete!\n",
      "All valid files: engine_data/all_data_Engine/\n",
      "Training data: engine_data/training_Engine/\n",
      "Testing data: engine_data/testing_Engine/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting AudioSet Engine Knocking data pooling and processing...\")\n",
    "pool_and_split_data(root_dir='engine_data', \n",
    "                    path_to_files='engine_data/engine_data_', \n",
    "                    type_of_sound=\"Engine\", \n",
    "                    delete_invalid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116a5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eld2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
